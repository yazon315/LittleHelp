{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a9f7c7",
   "metadata": {
    "id": "b3a9f7c7"
   },
   "source": [
    "## Визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb7e353",
   "metadata": {
    "id": "ebb7e353"
   },
   "source": [
    "#### Метод `.plot()` — построение графиков. ####\n",
    "\n",
    "Параметры метода `.plot()`:\n",
    "- `title` название графика (указывают строкой или переменной).\n",
    "- `style` вид отображения точек графика (`o` - кружок, `x` - крестик, `o-` - кружок и линия).\n",
    "- `x` и `y` им передаются значения столбцов датасета или списки для отображения по осям абсцисс и ординат соответственно.\n",
    "- `xlim` и `ylim` им передаются максимальные значения по осям абсцисс и ординат соответственно.\n",
    "- `grid` (пер. «сетка, решётка») отображает координаьную сетку, если равно `True`.\n",
    "- `figsize` (от англ. size of a figure — «размер фигуры») размер области построения графика. Ширину и высоту области построения в дюймах передают параметру в скобках: `figsize = (x_size, y_size)`.\n",
    "- `kind` (пер. «вид») вид графика, в данном случае `kind='hist'` — гистограмма. Значения параметра `kind`:\n",
    "    - `area` — график с накоплением;\n",
    "    - `bar` — вертикальная гистограмма (столбчатая диаграмма);\n",
    "    - `barh` — горизонтальная гистограмма;\n",
    "    - `box` — график с боксами;\n",
    "    - `hexbin` — шестнадцатеричный график (из шестигранных сот);\n",
    "    - `hist` — гистограмма;\n",
    "    - `kde` — график оценки плотности ядра;\n",
    "    - `density` — альтернативное название значения `kde`;\n",
    "    - `line` — линейный график (используется по умолчанию);\n",
    "    - `pie` — круговая диаграмма;\n",
    "    - `scatter` — диаграмма рассеяния.\n",
    "    ```python\n",
    "    df.plot(x='height', y='weight', kind='hexbin', gridsize=20, figsize=(8, 6), sharex=False, grid=True)\n",
    "    # hexbin — диаграмма рассеяния из шестиугольников, чем больше точек в области шестиугольника, тем темнее цвет\n",
    "    # gridsize — задает число шестиугольников по горизонтальной оси\n",
    "    # sharex=False — это «костыльный» обход бага библиотеки pandas, без него график будет неказистый\n",
    "    ```\n",
    "- `histtype` (от англ. the type of histogram — «тип гистограммы»). В параметре указывают тип гистограммы, по умолчанию — это столбчатая (закрашенная). Значение `step` (пер. «шаг») чертит только линию.\n",
    "- `linewidth` (от англ. width of line — «толщина линии»). Задаёт толщину линии графика в пикселях.\n",
    "- `alpha` (от термина «альфа-канал»). Назначает густоту закраски линии. `1` — это 100%-я закраска; `0` — прозрачная линия. С параметром `0.7` линии чуть прозрачны, так виднее их пересечения.\n",
    "- `label` (пер. «ярлык», «этикетка»). Название линии.\n",
    "- `ax` (от англ. axis — «ось»). Метод `plot()` возвращает оси, на которых был построен график. Чтобы обе гистограммы расположились на одном графике, сохраним оси первого графика в переменной `ax`, а затем передадим её значение параметру `ax` второго `plot()`. Так, сохранив оси одной гистограммы и построив вторую на осях первой, мы объединили два графика.\n",
    "- `legend` (пер. «легенда»). Выводит легенду — список условных обозначений на графике. На графике вы можете найти её в верхнем правом углу.\n",
    "\n",
    "Примеры:\n",
    "\n",
    "1. \n",
    "```python\n",
    "df.plot(title='A и B', x='b', y='a', style='o-', xlim=(0, 30), grid=True, figsize=(10, 3))\n",
    "```\n",
    "2. \n",
    "```python\n",
    "good_stations_stat.plot(\n",
    "    kind='hist',\n",
    "    y='time_spent',\n",
    "    histtype='step',\n",
    "    range=(0, 500),\n",
    "    bins=25,\n",
    "    linewidth=5,\n",
    "    alpha=0.7,\n",
    "    label='filtered',\n",
    "    ax=ax,\n",
    "    grid=True,\n",
    "    legend=True,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca5c02",
   "metadata": {
    "id": "19ca5c02"
   },
   "source": [
    "#### Метод `pd.plotting.scatter_matrix()` ####\n",
    "Строит матрицу попарных диаграмм рассеяния для столбцов датасета.\n",
    "```python\n",
    "hwa = pd.read_csv('hwa.csv', sep=';')\n",
    "pd.plotting.scatter_matrix(hwa, figsize=(9, 9))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea456d",
   "metadata": {
    "id": "4dea456d"
   },
   "source": [
    "#### Метод `.describe()` ####\n",
    "\n",
    "Отображение статистической информации о столбцах датафрейма.  \n",
    "Есть параметры `percentiles=`, `include=`, `exclude=` и `datetime_is_numeric=`.  \n",
    "\n",
    "\n",
    "```python\n",
    "display(data.describe())\n",
    "\n",
    "data.describe(include=['object', 'float', 'int']) # статистика только для столбцов с указанными типами данных\n",
    "\n",
    "data.describe(include='all').T # если столбцов много, то для удобства просмотра результат можно транспонировать\n",
    "```\n",
    "\n",
    "Построение гистограмм для каждого столбца\n",
    "```python\n",
    "data.hist(bins=100, figsize=(17,88), layout=(22,4))\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7de867",
   "metadata": {
    "id": "7f7de867"
   },
   "source": [
    "#### Метод `.corr()` ####\n",
    "Определяет коэффициент корреляции (от англ. correlation — «корреляция») Пирсона. Коэффициент Пирсона помогает определить наличие линейной связи между величинами и принимает значения от -1 до 1. Чем ближе к 1 или -1, тем сильнее положительная или отрицательная корреляция соответственно. Метод применяют к столбцу с первой величиной, а столбец со второй передают в параметре. Какая первая, а какая вторая — неважно:\n",
    "```python\n",
    "print(hw['height'].corr(hw['weight']))\n",
    "print(hw['weight'].corr(hw['height'])) # поменяли местами рост и вес\n",
    "\n",
    "# применительно к датасету с несколькими столбцами получим матрицу попарных коэффициентов корреляции столбцов датасета\n",
    "print(df.corr())\n",
    "```\n",
    "\n",
    "#### Построение матрицы корреляции ####\n",
    "\n",
    "Вариант 1\n",
    "```python\n",
    "plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(data.corr(), vmin = -1, vmax = +1, cmap = 'coolwarm', annot=True, linewidths=.1, linecolor='black')\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Матрица корреляции')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Вариант 2\n",
    "```python\n",
    "corrMatrix = df.select_dtypes(include=np.number).iloc[:, :7].corr()\n",
    "\n",
    "sns.set(style = 'white')\n",
    "# маска для формы графика в виде верхнего треугольника\n",
    "mask = np.triu(np.ones_like(corrMatrix, dtype=np.bool))\n",
    "# задание зоны построения графика в matplotlib\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "# построение хитмэпа по заданной маске и с правильным соотношением сторон\n",
    "sns.heatmap(corrMatrix, mask=mask, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da61a42",
   "metadata": {
    "id": "3da61a42"
   },
   "source": [
    "#### Построение графика распределения плотности `sns.kdeplot()` ####\n",
    "\n",
    "```python\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) \n",
    "\n",
    "# Density plot цены в каждом населенном пункте\n",
    "for locality in df_short.locality_name.unique():\n",
    "    sns.kdeplot(df_short[df_short.locality_name == locality].price_per_meter, label = locality)\n",
    "    \n",
    "plt.grid(True) # сетка\n",
    "plt.legend(loc = 'upper left', bbox_to_anchor = (1,1)) # положение легенды\n",
    "plt.title('Плотность распределения\\nцены за квадратный метр по населенным пунктам', loc = 'left') # название графика\n",
    "plt.xlabel('Цена за квадратный метр') # подпись оси x\n",
    "plt.xlim((0,250000)) # ограничение значений оси X\n",
    "ax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: '{}'.format(int(x/1000)) + 'K')) # форматирование подписей на оси X\n",
    "plt.annotate('Хвосты', size = 15, xy = (200000, 0.000003), xytext = (220000, 0.0000225), \n",
    "             arrowprops = dict(facecolor = 'gray', shrink = 0.1, width = 2)) # аннотация графика с заданной позицией\n",
    "plt.savefig('locality_comparison.png', bbox_inches = 'tight') # сохранение графика для презентации\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e956cf",
   "metadata": {
    "id": "96e956cf"
   },
   "source": [
    "## `DataFrame` и `Series`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b8740",
   "metadata": {
    "id": "267b8740"
   },
   "source": [
    "#### Добавление новых столбцов в датафрейм\n",
    "\n",
    "```python\n",
    "df1['new'] = df2['d']\n",
    "```\n",
    "\n",
    "При этом новый столбец `'new'` в датафрейме `df1` формируется из значений столбца `'d'` датафрейма `df2` строго по совпадению индексов датасетов.  \n",
    "*Пример.* Заменим индексы во втором датафрейме на значения столбца `c`. После чего присвоим столбцу `new` в первом датафрейме значения столбца `d` в `df2`:\n",
    "```python\n",
    "df1 = pd.DataFrame({'a': [1, 2, 3, 3, 3],\n",
    "                    'b': ['Q', 'R', 'S', 'T', 'U']})\n",
    "df2 = pd.DataFrame({'c': [3, 4, 5, 6, 7],\n",
    "                    'd': ['V', 'W', 'X', 'Y', 'Z'],\n",
    "                    'e': [3, 3, 3, 3, 3]})\n",
    "df2.set_index('c', inplace=True)\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)\n",
    "df1['new'] = df2['d']\n",
    "print()\n",
    "print(df1)\n",
    "```  \n",
    "*Результат:*  \n",
    "```python\n",
    "   a  b\n",
    "0  1  Q\n",
    "1  2  R\n",
    "2  3  S\n",
    "3  3  T\n",
    "4  3  U\n",
    "\n",
    "   d  e\n",
    "c\n",
    "3  V  3\n",
    "4  W  3\n",
    "5  X  3\n",
    "6  Y  3\n",
    "7  Z  3\n",
    "\n",
    "   a  b  new\n",
    "0  1  Q  NaN\n",
    "1  2  R  NaN\n",
    "2  3  S  NaN\n",
    "3  3  T    V\n",
    "4  3  U    W\n",
    "```\n",
    "\n",
    "Индексы в `df1` и `df2` уже не одинаковы. Присвоение происходит лишь по совпадающим индексам. В `df2` нет индексов `0`, `1`, `2` — в этих строках финального датафрейма оказались `NaN`. А в строках с индексами `3` и `4` записаны значения, которые в `df2['d']` были в строках с индексами `3` и `4`.  \n",
    "Если в `df1` будут повторяющиеся индексы, то значение из `df2['d']` скопируется несколько раз.  \n",
    "Число строк в `df2` не обязательно должно совпадать с числом строк `df1`. Если в `df2` не хватит значений, то будет подставлено `None`. Если будут лишние значения, то они просто не попадут в обновлённый датафрейм.  \n",
    "Повторяющиеся значения в индексе `df2` приведут к ошибке. В этом случае `pandas` не поймёт, какое из значений следует подставить в `df1`.  \n",
    "Аналогично, в соответствии с индексами, происходит добавление значений из `Series`.  \n",
    "```python\n",
    "series = pd.Series([1, 2, 3, 4, 5])  \n",
    "df1['new'] = series\n",
    "```\n",
    "*Результат:*  \n",
    "```python\n",
    "   b  new\n",
    "a        \n",
    "1  Q    2\n",
    "2  R    3\n",
    "3  S    4\n",
    "3  T    4\n",
    "3  U    4\n",
    "```  \n",
    "Если добавление столбца происходит из списка (`list`), то индексы не учитываются и происходит добавление всех значений из списка по порядку:  \n",
    "```python\n",
    "list_values = [1, 2, 3, 4, 5]  \n",
    "df1['new'] = list_values\n",
    "```  \n",
    "*Результат:*  \n",
    "```python\n",
    "   b  new\n",
    "a        \n",
    "1  Q    1\n",
    "2  R    2\n",
    "3  S    3\n",
    "3  T    4\n",
    "3  U    5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j50zlBPF1lfI",
   "metadata": {
    "id": "j50zlBPF1lfI"
   },
   "source": [
    "#### Создание датафрейма из словаря, назначение индексов, переименование индексов и столбцов.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "# создаем словарь из произвольных значений\n",
    "slovar = {'c': [3, 4, 5, 6, 7],\n",
    "          'd': ['V', 'W', 'X', 'Y', 'Z'],\n",
    "          'e': [3, 3, 3, 3, 3]}\n",
    "# создаем датафрейм_1, в котором ключи словаря станут столбцами (индексы появляются по умолчанию)\n",
    "df1 = pd.DataFrame(slovar)\n",
    "print('Датафрейм_1, в котором ключи словаря стали столбцами:\\n', df1,\n",
    "      '\\n')\n",
    "# создаем датафрейм_2, в котором ключи словаря станут строками (названия столбцов появляются по умолчанию)\n",
    "df2 = pd.DataFrame.from_dict(slovar, orient='index')\n",
    "print('Датафрейм_2, в котором ключи словаря стали строками:\\n', df2,\n",
    "      '\\n--------------------------')\n",
    "# назначаем индексами значения существующего столбца \"c\" датафрейма (столбец \"c\" заменяет собой индекс и исчезает из датасета)\n",
    "df1.set_index('c', inplace=True)\n",
    "print('Датафрейм_1 с индексами, созданными из столбца \"c\":\\n', df1,\n",
    "      '\\n')\n",
    "# переименовываем названия столбцов и индексов датафрейма\n",
    "df2.rename(columns={0:'A', 1:'B', 2:'C', 3:'D', 4:'E'}, index={'c':1, 'd':2, 'e':3}, inplace=True)\n",
    "print('Датафрейм_2 с переименованными названиями столбцов и индексов:\\n', df2)\n",
    "```\n",
    "\n",
    "Результат:\n",
    "\n",
    "```python\n",
    "Датафрейм_1, в котором ключи словаря стали столбцами:\n",
    "    c  d  e\n",
    "0  3  V  3\n",
    "1  4  W  3\n",
    "2  5  X  3\n",
    "3  6  Y  3\n",
    "4  7  Z  3 \n",
    "\n",
    "Датафрейм_2, в котором ключи словаря стали строками:\n",
    "    0  1  2  3  4\n",
    "c  3  4  5  6  7\n",
    "d  V  W  X  Y  Z\n",
    "e  3  3  3  3  3 \n",
    "--------------------------\n",
    "Датафрейм_1 с индексами, созданными из столбца \"c\":\n",
    "    d  e\n",
    "c      \n",
    "3  V  3\n",
    "4  W  3\n",
    "5  X  3\n",
    "6  Y  3\n",
    "7  Z  3 \n",
    "\n",
    "Датафрейм_2 с переименованными названиями столбцов и индексов:\n",
    "    A  B  C  D  E\n",
    "1  3  4  5  6  7\n",
    "2  V  W  X  Y  Z\n",
    "3  3  3  3  3  3\n",
    "```\n",
    "\n",
    "Второй способ переименования столбцов (если какой-либо столбец переименовывать не нужно, то ему присваивается значение 'no_name').\n",
    "\n",
    "```python\n",
    "id_name.columns = ['name', 'count']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe99bed",
   "metadata": {
    "id": "0fe99bed"
   },
   "source": [
    "#### Метод `pd.concat()` ####\n",
    "\n",
    "Соединение датафреймов.\n",
    "\n",
    "В аргументах у `pd.concat()`:\n",
    "- список из двух датафреймов - `[s1, s2]`;\n",
    "- датафреймы соединяются вертикально (количество столбцов не меняется, стороки складываются) - `axis=0`;\n",
    "- индекс у результирующего датафрейма сбрасывается - `ignore_index=True`.\n",
    "\n",
    "```python\n",
    "pd.concat([s1, s2], axis=0, ignore_index=True)\n",
    "```\n",
    "\n",
    "Соединение датафреймов с созданием многоуровневого (иерархического) индекса. В параметр `keys` передаются названия групп индекса, в параметр `names` передаются названия уровней индекса.\n",
    "```python\n",
    "by_shop = pd.concat([s1, s2], axis = 0, keys = ['s1', 's2'], names = ['s', 'id'])\n",
    "\n",
    "Результат:\n",
    "        item        price\n",
    "s   id\t\t\n",
    "s1  0   карандаш    220\n",
    "    1   ручка       340\n",
    "    2   папка       200\n",
    "    3   степлер     500\n",
    "s2  0   клей\t    200\n",
    "    1   корректор   240\n",
    "    2   скрепка     100\n",
    "    3   бумага      300\n",
    "```\n",
    "\n",
    "Соединение датафреймов горизонтально (`s2` справа от `s1`) за счет `axis = 1` с созданием групп многоуровневого индекса столбцов `keys = ['s1', 's2']`.\n",
    "\n",
    "```python\n",
    "pd.concat([s1, s2], axis = 1, keys = ['s1', 's2'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e81d3",
   "metadata": {
    "id": "f12e81d3"
   },
   "source": [
    "#### Метод `.merge()` ####\n",
    "\n",
    "Объединяет (соединяет) датафреймы.  \n",
    "В параметре `on` передается название столбца, по которому необходимо объединять датафреймы. Если столбец индекса именованный, его имя также можно передать параметру `on`. Чтобы объединять по нескольким столбцам сразу, нужно передать их список параметру `on`.  \n",
    "Режим слияния (объединения) задаётся параметром `how` (от англ. «как, каким образом») со следующими значениями: \n",
    "- Если `how` = `'inner'` (от англ. «внутренний», здесь значит «пересечение данных»), то финальный датафрейм складывается из совпадений значений, которые есть в обоих датафреймах в столбце по которому идет объединение. В методе `.merge()` тип `'inner'` работает по умолчанию.\n",
    "- Если `how` = `'outer'` (от англ. «внешний», здесь значит «объединение данных»), то финальный датафрейм складывается из значений, которые есть хотя бы в одном из объединяемых датафреймов в столбце по которому идет объединение. Если каких-то данных при таком объединении не будет, то в ячейках будет проставлено `NaN`.\n",
    "- Режим объединения `'left'` указывает, что в результат слияния обязательно должны войти все строки из левого датафрейма и совпадающие строки из правого.\n",
    "- В режиме `'right'` сохранятся все совпадающие строки и правый датафрейм.\n",
    "\n",
    "Окончания названий столбцов задают в параметре `suffixes`.\n",
    "\n",
    "```python\n",
    "first_pupil_df.merge(second_pupil_df, on='author', how='left', suffixes=('_записал первый', '_записал второй'))\n",
    "```\n",
    "\n",
    "Соединение двух датафреймов `math` и `math_degree` по индексам левого и правого датафрейма (`left_index = True, right_index = True`). Параметр `indicator = True` добавляет в результирующий детесет столбец с названием `_merge`, который содержит информацию из какого исходного датасета каждая строка.\n",
    "```python\n",
    "pd.merge(math, math_degree, how = 'left', left_index = True, right_index = True, indicator = True)\n",
    "```\n",
    "\n",
    "\n",
    "#### Метод `pd.merge_asof()` ####\n",
    "\n",
    "Соединение с условиями.\n",
    "```python\n",
    "pd.merge_asof(trades, quotes, # соединение двух датафреймов\n",
    "              on = 'time', # по столбцу времени time\n",
    "              by = 'ticker', # так, чтобы совпадало значение столбца ticker\n",
    "              tolerance = pd.Timedelta('10ms'), # совпадение по времени должно составлять менее 10 миллисекунд\n",
    "              direction = 'nearest') # можно искать совпадение в предыдущих и будущих периодах\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec62e9",
   "metadata": {
    "id": "5cec62e9"
   },
   "source": [
    "#### Метод `.join()` ####\n",
    "Объединяет (соединяет) датафреймы. Без параметра `on` метод `.join()` будет искать совпадения по индексам в первом и втором датафреймах. Если передать параметру `on` столбец, то метод `.join()` найдёт его в первом датафрейме и начнёт сравнивать с индексом второго. По умолчанию в `.join()` установлен тип слияния `how='left'`. Параметры `lsuffix` и `rsuffix` добавляют окончания (суффиксы) к названиям столбцов в объединенном датафрейме. Методом `.join()` можно объединять больше двух таблиц (их набор передают списком вместо второго датафрейма).\n",
    "```python\n",
    "df1 = pd.DataFrame({'a': [1, 2, 3, 4], 'b': ['A', 'B', 'C', 'D']})\n",
    "df2 = pd.DataFrame({'a': [2, 2, 2, 2], 'c': ['E', 'F', 'G', 'H']})\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)\n",
    "print()\n",
    "print (df1.join(df2, on='a', rsuffix='_y')['c'])\n",
    "```\n",
    "Результат:\n",
    "```python\n",
    "     a  b\n",
    "0  1  A\n",
    "1  2  B\n",
    "2  3  C\n",
    "3  4  D\n",
    "\n",
    "     a  c\n",
    "0  2  E\n",
    "1  2  F\n",
    "2  2  G\n",
    "3  2  H\n",
    "\n",
    "0      F\n",
    "1      G\n",
    "2      H\n",
    "3    NaN\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9775a7",
   "metadata": {
    "id": "8d9775a7"
   },
   "source": [
    "#### Метод `.groupby()` ####\n",
    "\n",
    "Создает объект `DataFrameGroupBy` к которому затем можно применить какой-нибудь метод или атрибут.\n",
    "\n",
    "Атрибут `.ngroups` показывает, сколько после активации метода `.groupby()` было создано групп:\n",
    "```python\n",
    "titanic.groupby('Sex').ngroups\n",
    "```\n",
    "\n",
    "Атрибут `.groups` выводит индекс наблюдений, отнесенных к каждой из групп.  \n",
    "Выберем группу `female` (по ключу словаря) и выведем первые пять индексов (через срез списка), относящихся к этой группе:\n",
    "```python\n",
    "titanic.groupby('Sex').groups['female'][:5]\n",
    "\n",
    "Результат:\n",
    "    Int64Index([1, 2, 3, 8, 9], dtype='int64')\n",
    "```\n",
    "\n",
    "Метод `.size()` показывает количество элементов в каждой группе:\n",
    "```python\n",
    "titanic.groupby('Sex').size()\n",
    "```\n",
    "\n",
    "Метод `.first()` выдает первые встречающиеся наблюдения в каждой из групп.  \n",
    "Метод `.last()` выдает последние встречающиеся наблюдения в каждой из групп.\n",
    "```python\n",
    "titanic.groupby('Sex').first()\n",
    "```\n",
    "\n",
    "Метод `.get_group()` позволяет выбрать наблюдения только одной группы.  \n",
    "Выберем наблюдения группы `male` и выведем первые пять строк датафрейма:\n",
    "```python\n",
    "titanic.groupby('Sex').get_group('male').head()\n",
    "```\n",
    "\n",
    "Вывод медианного возраста (по столбцу `Age`) мужчин и женщин (группировка по столбцу `Sex`) с округлением до одного знака (`.round(1)`):\n",
    "```python\n",
    "titanic.groupby('Sex').Age.median().round(1)\n",
    "```\n",
    "\n",
    "Вывод статистики по нескольким столбцам: рассчет среднего арифметического по столбцам `Age` и `Fare` для каждого из классов `Pclass` с округлением (`.round(1)`).\n",
    "```python\n",
    "titanic.groupby('Pclass')[['Age', 'Fare']].mean().round(1)\n",
    "```\n",
    "\n",
    "Группировка по двум признакам `Pclass` и `Sex` с расчетом количества наблюдений в каждой подгруппе по каждому столбцу методом `.count()`:\n",
    "```python\n",
    "titanic.groupby(['Pclass', 'Sex']).count()\n",
    "```\n",
    "\n",
    "Можно использовать метод `.groupby()` как аналог метода `pd.pivot_table()` при группировке по строкам:\n",
    "```python\n",
    "bmw.groupby(by = ['state', 'year'])[['price']].agg('median')\n",
    "\n",
    "Результат:\n",
    "                    price\n",
    "state       year\t\n",
    "california  2017    39800.0\n",
    "            2020    61200.0\n",
    "florida     2013    2925.0\n",
    "georgia     2008    1825.0\n",
    "illinois    2014    15000.0\n",
    "michigan    2016    39000.0\n",
    "            2017    39000.0\n",
    "new jersey  2014    13500.0\n",
    "tennessee   2017    29400.0\n",
    "texas       2011    6200.0\n",
    "            2016    29700.0\n",
    "utah        2000    0.0\n",
    "wisconsin   2017    26600.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44913519",
   "metadata": {
    "id": "44913519"
   },
   "source": [
    "#### Метод `.agg()` ####\n",
    "\n",
    "Одновременное нахождение максимального и минимального значений, количества наблюдений, медианы и среднего арифметического по столбцу `Age` после группировки по столбцу `Sex` с округлением (`.round(1)`):\n",
    "```python\n",
    "titanic.groupby('Sex').Age.agg(['max', 'min', 'count', 'median', 'mean']).round(1)\n",
    "```\n",
    "\n",
    "Для удобства при группировке и расчете показателей столбцы можно переименовывать:\n",
    "```python\n",
    "titanic.groupby('Sex').Age.agg(sex_max = ('max'), sex_min = ('min'))\n",
    "\n",
    "Результат:\n",
    "        sex_max  sex_min\n",
    "Sex\t\t\n",
    "female  63.0     0.75\n",
    "male    80.0     0.42\n",
    "```\n",
    "\n",
    "Применение метода `.agg()` к нескольким столбцам: рассчет среднего арифметического и медианы для столбцов `Age` и `Fare`.\n",
    "```python\n",
    "titanic.groupby('Sex')[['Age', 'Fare']].agg(['mean', 'median']).round(1)\n",
    "\n",
    "Результат:\n",
    "            Age               Fare\n",
    "        mean    median    mean    median\n",
    "Sex\t\t\t\t\n",
    "female  27.9    27.0      44.5    23.0\n",
    "male    30.7    29.0      25.5    10.5\n",
    "```\n",
    "\n",
    "Использование пользовательской функции. Функция `below29()` выдает `True`, если средний возраст меньше 29 лет и `False` в остальных случаях. Функция `below29()` применяется к группам `female` и `male`, образованным при группировке по столбцу `Sex`.\n",
    "```python\n",
    "def below29(x):\n",
    "    m = x.mean()\n",
    "    return True if m < 29 else False\n",
    "\n",
    "titanic.groupby('Sex').Age.agg(['max', 'mean', below29])\n",
    "\n",
    "Результат:\n",
    "        max    mean        below29\n",
    "Sex\t\t\t\n",
    "female  63.0   27.915709   True\n",
    "male    80.0   30.726645   False\n",
    "```\n",
    "\n",
    "Для данных, сгруппированных по столбцу `is_apartment`, по столбцу `last_price` считают среднее и медиану, а по столбцу `total_area` находят максимальное значение:\n",
    "```python\n",
    "df.groupby('is_apartment').agg({'last_price': ['mean', 'median'], 'total_area': 'max'})\n",
    "```\n",
    "\n",
    "При группировке столбцу со средними значениями дается название `last_price_mean`, с столбцу с медианными значениями - название `last_price_median` и сбрасывается индекс (`reset_index()`):\n",
    "```python\n",
    "df.groupby('is_apartment').agg(last_price_mean = ('last_price', 'mean'), last_price_median = ('last_price', 'median')\n",
    "                              ).reset_index()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a6d13",
   "metadata": {
    "id": "343a6d13"
   },
   "source": [
    "#### Метод `.filter()` ####\n",
    "\n",
    "Фильтрация по условию.\n",
    "\n",
    "Вывод первых строк (`.head()`) только тех классов кают `Pclass`, в которых среднегрупповой возраст `Age` не менее 26 лет:\n",
    "```python\n",
    "titanic.groupby('Pclass').filter(lambda x: x['Age'].mean() >= 26).head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843977d4",
   "metadata": {
    "id": "843977d4"
   },
   "source": [
    "#### Метод `.query()` ####\n",
    "\n",
    "Позволяет отфильтровать данные по условию.\n",
    "```python\n",
    "df.query('price > 20000')\n",
    "\n",
    "data.query('total_income != total_income and days_employed != days_employed') # пропущенные значения в total_income и days_employed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb523b45",
   "metadata": {
    "id": "cb523b45"
   },
   "source": [
    "#### Метод `pd.pivot_table()` или `.pivot_table()` ####\n",
    "\n",
    "Формирование сводных таблиц.\n",
    "\n",
    "- Возможные значения параметра `aggfunc=`:\n",
    "    - `median` — медианное значение;\n",
    "    - `count` — количество значений;\n",
    "    - `sum` — сумма значений;\n",
    "    - `min` — минимальное значение;\n",
    "    - `max` — максимальное значение;\n",
    "    - `first` — первое значение из группы;\n",
    "    - `last` — последнее значение из группы;\n",
    "    - пользовательские функции.\n",
    "\n",
    "- Метод `.style.format()` позволяет настроить формат вывода данных указанных столбцов датасета. Например, вывод значений столбца `debt` в процентах с двумя знаками после запятой: `data.groupby('family_status')[['debt']].mean().sort_values(['debt']).style.format({'debt': '{:.2%}'})`.  \n",
    "- Метод `.style.background_gradient()` позволяет добавить цветовую маркировку. Например: `.style.background_gradient(cmap='coolwarm')`.  \n",
    "- Для выделения пропущенных значений используется метод `.style.highlight_null()`, при этом цвет выбирается через параметр `null_color`. Например: `.style.highlight_null(null_color='yellow')`.  \n",
    "- На основе сводных таблиц можно сразу строить графики, добавляя метод `.plot`. Например: `.plot.barh(figsize=(10,7), title='Clean vs. Salvage Counts')`.  \n",
    "- Метод `.style.bar()` позволяет создать встроенную горизонтальную столбчатую диаграмму. Цвет в параметр `color` можно передавать, в том числе, в hex-формате: `.style.bar(color = '#d65f5f')`.\n",
    "\n",
    "Группировка данных по строкам в датасете `cars` по марке `brand`, а затем по цвету кузова `color`. Для каждой подгруппы рассчитывается медиана `median` и количество наблюдений `count`:\n",
    "```python\n",
    "pd.pivot_table(cars, index = ['brand', 'color'], values = 'price', aggfunc = ['median', 'count']).round(2).head(11)\n",
    "\n",
    "Результат:\n",
    "                    median   count\n",
    "                    price    price\n",
    "brand   color\t\t\n",
    "acura   black       3900.0   1\n",
    "        gray        1000.0   1\n",
    "        silver\t    16900.0\t 1\n",
    "audi    black       25.0     3\n",
    "        blue        19500.0  1\n",
    "bmw     black       34200.0  4\n",
    "        blue        39000.0  5\n",
    "        gray        15350.0  4\n",
    "        no_color    29700.0  1\n",
    "        silver      15000.0  1\n",
    "        white       2375.0   2\n",
    "```\n",
    "\n",
    "Выведем медианную цену `median` и количество `count` по столбцу `price` для каждой марки `brand` с разбивкой по категориям, имеющимся в столбце `title_status`, а также применим метод `.transpose()`, чтобы поменять строки и столбцы местами (транспонировать):\n",
    "```python\n",
    "pd.pivot_table(cars,\n",
    "               index = 'brand',\n",
    "               columns = 'title_status',\n",
    "               values = 'price',\n",
    "               aggfunc = ['median', 'count']).round().head().transpose()\n",
    "\n",
    "Результат:\n",
    "    \tbrand              acura    audi     bmw      buick    cadillac\n",
    "        title_status\t\t\t\t\t\n",
    "median  clean vehicle      10400.0  27950.0  31600.0  20802.0  24500.0\n",
    "        salvage insurance  1000.0   12.0     1825.0   0.0      0.0\n",
    "count   clean vehicle      2.0      2.0      14.0     12.0     9.0\n",
    "        salvage insurance  1.0      2.0      3.0      1.0      1.0\n",
    "```\n",
    "\n",
    "Mетод `.unstack()` как бы убирает второе измерение. Данные группируются по имеющимся признакам в столбце `brand` и в столбце `title_status`, но признаки из `title_status` не становятся столбцами, а вместе с `index='brand'` образуют мультииндекс в строках:\n",
    "```python\n",
    "pd.pivot_table(cars, index='brand', columns='title_status', values='price', aggfunc='median').round(2).head().unstack()\n",
    "\n",
    "Результат:\n",
    "title_status       brand   \n",
    "clean vehicle      acura       10400.0\n",
    "                   audi        27950.0\n",
    "                   bmw         31600.0\n",
    "                   buick       20802.5\n",
    "                   cadillac    24500.0\n",
    "salvage insurance  acura        1000.0\n",
    "                   audi           12.5\n",
    "                   bmw          1825.0\n",
    "                   buick           0.0\n",
    "                   cadillac        0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc43027",
   "metadata": {
    "id": "ecc43027"
   },
   "source": [
    "#### Метод `.replace()` ####\n",
    "\n",
    "Замена значений в датасете.\n",
    "\n",
    "```python\n",
    "# замена -1 на 0 в столбце 'children'\n",
    "data['children'] = data['children'].replace(-1, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286c11a9",
   "metadata": {
    "id": "286c11a9"
   },
   "source": [
    "#### Метод `.clip()` ####\n",
    "\n",
    "Обрезание выбросов путем установки границ диапазона значений. Значения больше верхней границы диапазона приравниваются к верхней границе. Аналогичные действия с нижней границей.\n",
    "\n",
    "```python\n",
    "data['days_employed']=data['days_employed'].clip(90, 18250) # значения в столбце days_employed ограничиваются диапазоном от 90 до 18250\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32929dfa",
   "metadata": {
    "id": "32929dfa"
   },
   "source": [
    "#### Метод `.where()` ####\n",
    "\n",
    "Выборочно изменяет значения в датафрейме. Ему передают два параметра: условие для булева массива и новые значения. Если условие равно `True`, то соответствующее ему значение не изменится, если `False`, то значение поменяется на второй параметр метода.\n",
    "\n",
    "```python\n",
    "shopping = pd.Series(['молоко', 'хамон', 'хлеб', 'картошка', 'огурцы'])\n",
    "# Ниже задано условие для булева массива, проверяющее, не оказался ли элемент списка хамоном: `shopping != 'хамон'`. \n",
    "# В результате проверки получается массив вида: `[True, False, True, True, True]`. \n",
    "# Строки со значением `True` не изменились, а `хамон` поменялся на значение `обойдусь`.\n",
    "print(shopping.where(shopping != 'хамон', 'обойдусь'))  \n",
    "```\n",
    "\n",
    "Замена возраста всех, кому меньше 18, на `NaN`:\n",
    "```python\n",
    "people.age.where(people.age >= 18, other = np.nan)\n",
    "```\n",
    "\n",
    "Если число в датафрейме `nums` положительное, то оно остается без изменений. Если отрицательное, то заменяется на обратное/противоположное (т.е. становится положительным):\n",
    "```python\n",
    "nums.where(nums > 0, other = -nums)\n",
    "```\n",
    "\n",
    "#### Функция `np.where()` ####\n",
    "\n",
    "Внутри функции `np.where()` три параметра:\n",
    "1. условие;\n",
    "2. значение, если условие выдает `True`;\n",
    "3. значение, если условие выдает `False`.\n",
    "```python\n",
    "# в столбце 'age_group' записывает 'adult', если в столбце 'age' число больше 18, иначе записывает 'minor'\n",
    "people['age_group'] = np.where(people['age'] >= 18, 'adult', 'minor')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94909472",
   "metadata": {
    "id": "94909472"
   },
   "source": [
    "#### Метод `map()`\n",
    "\n",
    "Создадим карту (map) (по сути - переменную) с правилом, как преобразовать существующие значения в новые. Такая карта представляет собой питоновский словарь, где ключи - это существующие данные, а значения - новые. Передадим эту переменную в метод `.map()` для обработки выбранного столбца.\n",
    "\n",
    "```python\n",
    "gender_map = {0: 'female', 1 : 'male'}\n",
    "people['gender'] = people['gender'].map(gender_map)\n",
    "```\n",
    "В метод `.map()` можно передать lambda-функцию. Например, для того, чтобы выявить совершеннолетних и несовершеннолетних людей:\n",
    "```python\n",
    "people['age_group'] = people['age'].map(lambda x: 'adult' if x >= 18 else 'minor')\n",
    "```\n",
    "Заполнение пропусков случайным значеним от 1 до 21:\n",
    "```python\n",
    "df['price'] = df['price'].map(lambda x: x if not np.isnan(x) else np.random.choice(range(1, 21)))\n",
    "```\n",
    "\n",
    "Или передать обычную функцию (`get_age_group`).  \n",
    "В такую функцию нельзя передать дополнительные аргументы. В функцию передаются только те данные, к которым применяется `.map()`. В нашем случае - это `people['age']`.\n",
    "```python\n",
    "def get_age_group(age):\n",
    "    threshold = 18 # порог приходится фиксированно задавать внутри функции\n",
    "    if age >= threshold:\n",
    "        age_group = 'adult'\n",
    "    else:\n",
    "        age_group = 'minor'\n",
    "    return age_group\n",
    "\n",
    "people['age_group'] = people['age'].map(get_age_group)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9741c",
   "metadata": {
    "id": "a9f9741c"
   },
   "source": [
    "#### Метод `.apply()` ####\n",
    "\n",
    "- _Применение к аргументам:_\n",
    "\n",
    "    Метод `.apply()` (в отличие от `.map()`) позволяет передавать аргументы в применяемую функцию. Объявим функцию `get_age_group`, которой можно передать не только значение возраста, но и порог, при котором человек будет считаться совершеннолетним. Затем применим эту функцию к столбцу `age`, выбрав в качестве порогового значения 21 год.\n",
    "\n",
    "```python\n",
    "def get_age_group(age, threshold):\n",
    "    if age >= int(threshold):\n",
    "        age_group = 'adult'\n",
    "    else:\n",
    "        age_group = 'minor'\n",
    "    return age_group\n",
    "\n",
    "people['age_group'] = people['age'].apply(get_age_group, threshold = 21)\n",
    "```\n",
    "\n",
    "- _Применение к столбцам:_\n",
    "\n",
    "    Замена значений в столбцах `height` и `weight` на медиану столбцов:\n",
    "```python\n",
    "people[['height', 'weight']] = people[['height', 'weight']].apply(np.median, axis=0)\n",
    "```\n",
    "    В датасет `df_km_distance` сохраняются значения из четырех столбцов датасета `df`, разделенные на 1000:\n",
    "```python\n",
    "distance_cols = ['airports_nearest', 'cityCenters_nearest', 'parks_nearest', 'ponds_nearest']\n",
    "df_km_distance = df[distance_cols].apply(lambda x: x / 1000)\n",
    "```\n",
    "\n",
    "- _Применение к строкам:_\n",
    "\n",
    "    Создадим функцию `get_bmi`, которая рассчитает индекс массы тела, применим ее к каждой строке (человеку) и сохраним результат в новом столбце:\n",
    "\n",
    "```python\n",
    "def get_bmi(x):\n",
    "    bmi = x['weight'] / (x['height'] / 100) ** 2\n",
    "    return bmi\n",
    "\n",
    "people['bmi'] = people.apply(get_bmi, axis=1).round(2)\n",
    "```\n",
    "\n",
    "\n",
    "#### Метод `.applymap()` ####\n",
    "\n",
    "Создадим датафрейм `nums` из чисел. Объявим функцию `add_number`, которая на входе принимает число `x` и прибавляет к нему другое число, указанное в параметре `number`. Передадим методу `.applymap()` функцию `add_number` и тем самым прибавим единицу к каждому элементу датафрейма.\n",
    "\n",
    "```python\n",
    "nums_matrix = [[13, 7, 1],\n",
    "               [4, 2, 25],\n",
    "               [45, 3, 8]]\n",
    "nums = pd.DataFrame(nums_matrix)\n",
    "\n",
    "def add_number(x, number):\n",
    "    return x + number\n",
    "\n",
    "nums.applymap(add_number, number = 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31f4f0",
   "metadata": {
    "id": "5b31f4f0"
   },
   "source": [
    "#### Метод `.pipe()` ####\n",
    "\n",
    "Позволяет запускать конвейером несколько функций (как пайплайн).\n",
    "\n",
    "```python\n",
    "# функция копирования датафрейма\n",
    "def copy_df(df):\n",
    "   return df.copy()\n",
    "\n",
    "# функция замены значений столбца на новые с помощью метода .map() \n",
    "def map_column(df, column, label1, label2):\n",
    "  labels_map = {0: label1, 1 : label2}\n",
    "  df[column] = df[column].map(labels_map)\n",
    "  return df\n",
    "\n",
    "# функция превращения количественной переменной в бинарную категориальную\n",
    "def to_categorical(df, newcol, condcol, thres, cat1, cat2):\n",
    "  df[newcol] = np.where(df[condcol] >= thres, cat1, cat2)\n",
    "  return df\n",
    "\n",
    "# последовательное применение функций с помощью нескольких методов .pipe()\n",
    "people_processed = (people.\n",
    "                    pipe(copy_df). # copy_df() применится ко всему датафрейму\n",
    "                    pipe(map_column, 'gender', 'female', 'male'). # map_column() к столбцу gender\n",
    "                    pipe(to_categorical, 'age_group', 'age', 18, 'adult', 'minor')) # to_categorical() к age_group\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65112cf2",
   "metadata": {
    "id": "65112cf2"
   },
   "source": [
    "#### Использование `include` и `exclude`\n",
    "\n",
    "Выберем столбцы только с типами данных `int` и `float`:\n",
    "```python\n",
    "countries.select_dtypes(include = ['int64', 'float64'])\n",
    "```\n",
    "\n",
    "Выберем столбцы с любыми типами данных, кроме `object` и `category`:\n",
    "```python\n",
    "countries.select_dtypes(exclude = ['object', 'category'])\n",
    "```\n",
    "\n",
    "Выбрать все столбцы у которых в названии есть `nearest`:\n",
    "```python\n",
    "distance_cols = [col for col in df.columns if 'nearest' in col] # вариант 1\n",
    "\n",
    "distance_cols = df.columns[df.columns.str.contains('nearest')] # вариант 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737b31d",
   "metadata": {},
   "source": [
    "#### Замена значений в датафрейме по условию\n",
    "\n",
    "1. С помощью метода `.loc`.\n",
    "\n",
    "```python\n",
    "df.loc[df['column_name'] == 'заменяемое_значение', 'column_name'] = 'значение_на_которое_заменяют'\n",
    "```\n",
    "\n",
    "2. С помощью функции `np.where()`.\n",
    "\n",
    "```python\n",
    "df['column_name'] = np.where(df['column_name'] == 'заменяемое_значение', 'заменяющее_значение_если_условие_выполняется', 'заменяющее_значение_если_условие_НЕ_выполняется')\n",
    "```\n",
    "\n",
    "3. С помощью метода `.mask`.\n",
    "\n",
    "```python\n",
    "df['column_name'].mask( df['column_name'] == 'заменяемое_значение', 'заменяющее_значение' , inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef699b",
   "metadata": {
    "id": "edef699b"
   },
   "source": [
    "## Разное"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4a53c",
   "metadata": {},
   "source": [
    "#### Переустановка и удаление библиотек Python\n",
    "\n",
    "В Windows 10, если нужно использовать команду `pip` в комендной строке Windows `cmd` (а не только в командной строке Anaconda), необходимо добавить 3 пути среды в Path (название пути зависит от того, куда устанавливали Anaconda):\n",
    "```\n",
    "C:\\Users\\Victor\\anaconda3 \n",
    "C:\\Users\\Victor\\anaconda3\\Scripts\n",
    "C:\\Users\\Victor\\anaconda3\\Library\\bin\n",
    "```\n",
    "\n",
    "*Вывести список всех установленных библиотек с их версиями:*\n",
    "```\n",
    "pip freeze\n",
    "```\n",
    "или\n",
    "```\n",
    "pip list\n",
    "```\n",
    "или подробная информация о конкретной библиотеке (с названием `name`):\n",
    "```\n",
    "pip show name\n",
    "```\n",
    "\n",
    "*Обновление библиотеки (name - название обновляемой библиотеки):*\n",
    "```\n",
    "pip install --upgrade name\n",
    "```\n",
    "\n",
    "*Переустановка библиотеки:*\n",
    "```\n",
    "pip install --upgrade --no-deps --force-reinstall name\n",
    "```\n",
    ", где:\n",
    "- --upgrade: обновить все указанные пакеты до последней доступной версии;\n",
    "- --no-deps: не устанавливать зависимости пакетов, если предполагается, что зависимости не требуют переустановки (зависимости - библиотеки от которых зависит эта библиотека);\n",
    "- --force-reinstall: переустановить все пакеты, даже если они уже обновлены до последней версии;\n",
    "- name: название библиотеки.\n",
    "\n",
    "*Переустановка библиотеки и всех её зависимостей без удаления текущих версий (name - название библиотеки):*\n",
    "```\n",
    "pip install --ignore-installed name\n",
    "```\n",
    "\n",
    "*Переустановить или установить дополнительно библиотеку нужной версии:*\n",
    "```\n",
    "pip install --force-reinstall -v \"name==1.2.2\"\n",
    "```\n",
    ", где:\n",
    "- --force-reinstall: переустановка версии вместо текущей (если не указывать этот параметр, то будет установлена указанная версия библиотеки без удаления ужеверсии, которая уже установлена);\n",
    "- -v: количество подробностей обтображения информации (verbose), может быть -v, -vv или -vvv;\n",
    "- name: название библиотеки;\n",
    "- 1.2.2: конкретная версия библиотеки.\n",
    "\n",
    "Можно установить диапазон версий библиотеки (если имеющиеся версии перед этим нужно удалить, то устанавливают параметр --force-reinstall), например:\n",
    "```\n",
    "pip install 'stevedore>=1.3.0,<1.4.0' --force-reinstall\n",
    "```\n",
    "\n",
    "*Удаление библиотеки (name - имя удаляемой библиотеки):*\n",
    "```\n",
    "pip uninstall name\n",
    "```\n",
    "\n",
    "Если установлено несколько версий одной библиотеки, то сделать соответствующее количество раз `pip uninstall name`.\n",
    "\n",
    "*Можно удалять (или устанавливать) через `python`, как среду для `pip`:*\n",
    "```\n",
    "python -m pip uninstall name\n",
    "```\n",
    "\n",
    "*Можно просто удалить с компьютера папку, где находится библиотека:*\n",
    "\n",
    "Просмотр каталога, где установлен пакет, - `.__path__`. Просмотр файла, где находится модуль, - `.__file__`. Пример:\n",
    "```python\n",
    "import pandas as pd\n",
    "print(pd.__path__)\n",
    "print(pd.__file__)\n",
    "```\n",
    "Результат:\n",
    "```\n",
    "['c:\\\\Users\\\\Victor\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas']\n",
    "c:\\Users\\Victor\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6MWY59w9DTvv",
   "metadata": {
    "id": "6MWY59w9DTvv"
   },
   "source": [
    "#### Команды чтения и записи файлов в `pandas`\n",
    "\n",
    "|Чтение|Запись|\n",
    "|:----:|:----:|\n",
    "|read_csv\t|to_csv\n",
    "|read_excel\t|to_excel\n",
    "|read_hdf\t|to_hdf\n",
    "|read_sql\t|to_sql\n",
    "|read_json\t|to_json\n",
    "|read_html\t|to_html\n",
    "|read_stata\t|to_stata\n",
    "|read_clipboard\t|to_clipboard\n",
    "|read_pickle\t|to_pickle\n",
    "|read_msgpack\t|to_msgpack (экспериментальный)\n",
    "|read_gbq\t|to_gbq (экспериментальный)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a80bc1",
   "metadata": {},
   "source": [
    "#### Конструкция `try - except`\n",
    "\n",
    "Применяется для обработки исключений (отслеживания ошибок без прерывания выполнения кода).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20bd83d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка! Вы ввели gzb а нужно ввести целое число.\n",
      "Конец\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    inp = input('Введите целое число:') # ожидание ручного ввода\n",
    "    x = int(inp) # преобразование введенного в целое число\n",
    "except ValueError:\n",
    "    print('Ошибка! Вы ввели', inp, 'а нужно ввести целое число.')\n",
    "else:\n",
    "    print('Верно. Вы ввели число.')\n",
    "    print('Ваше число:', x)\n",
    "    print('Ваше число во второй степени:', x*x)\n",
    "finally:\n",
    "    print('Конец') # то, что указано после finally выполнится в любом случае\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e261f",
   "metadata": {},
   "source": [
    "#### Конструкция `with - as`\n",
    "\n",
    "Применяется для обязательного выполнения каких-либо критических функций, даже если произойдет ошибка или пользователь забудет это сделать (например, если открыли файл, то его нужно обязательно закрыть)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f44dbfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# открываем файл 'test.txt' для записи и чтения 'a+' в кодировке 'utf-8' и сохраняем его в переменной file\n",
    "# записывем в файл фразу 'Новая запись'\n",
    "# за счет того, что функция открытия файла open находится внутри конструкции with-as, после выхода из конструкции, файл будет закрыт\n",
    "with open('test.txt', mode='a+', encoding='utf-8') as file:\n",
    "\tfile.write (\"\\nНовая запись в конце файла\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JX-nEEms1ADf",
   "metadata": {
    "id": "JX-nEEms1ADf"
   },
   "source": [
    "#### Снятие ограничении на количество отображаемых строк, столбцов и количества символов в ячейке таблиц датасетов\n",
    "\n",
    "``` python\n",
    "# сброс ограничений на количество выводимых строк\n",
    "pd.set_option('display.max_rows', None)\n",
    "# сброс ограничений на число столбцов\n",
    "pd.set_option('display.max_columns', None)\n",
    "# сброс ограничений на количество символов в ячейке\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# установка отображения 10 строк (5 первых и 5 последних)\n",
    "# (нечетные значения округляются до ближайшего меньшего четного)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "# установка отображения 6 столбцов (3 первых и 3 последних)\n",
    "# (нечетные значения округляются до ближайшего меньшего четного)\n",
    "pd.set_option('display.max_columns', 6)\n",
    "# установка отображения до 15 символов в ячейке\n",
    "pd.set_option('display.max_colwidth', 15)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdafb2d",
   "metadata": {
    "id": "9cdafb2d"
   },
   "source": [
    "#### Отключение и включение экспоненциального представления чисел (в формате 10 в степени)\n",
    "\n",
    "Глобально для чисел с плавающей запятой:\n",
    "```python\n",
    "pd.set_option('display.float_format', lambda x: '%.9f' % x) # отключить - устанавливается более высокая точность после запятой (9 знаков)\n",
    "pd.reset_option('display.float_format', silent=True) # сброс к исходным настройкам\n",
    "df['big float'].apply(lambda x: '%.9f' % x) # для датасета\n",
    "```\n",
    "Ещё вариант: `df.to_html(float_format='{:10.9f}'.format)` , где `{:10.9f}` можно прочитать так:\n",
    "- `10` - указывает общую длину числа, включая десятичную часть\n",
    "- `9` - используется для указания 9 знаков после запятой  \n",
    "Другие примеры: `{:30,.18f}` и `{:,.3f}`\n",
    "\n",
    "```python\n",
    "pd.options.display.float_format = '{:20,.2f}'.format # глобально (20 знаков до запятой, 2 знака - после запятой)\n",
    "# '{: .2f}' - любое количество знаков до запятой (пробел вместо числа)\n",
    "print('{:20,.8f}'.format(12333344445676.0123456789)) # использование с командой `print`\n",
    "```\n",
    "\n",
    "Отключение экспоненциального представления чисел на графиках:\n",
    "```python\n",
    "plt.ticklabel_format(style='plain')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02c02e",
   "metadata": {},
   "source": [
    "#### Измерение времени \n",
    "\n",
    "Команда `%%time`. Показывает время выполнения ячейки с кодом.\n",
    "\n",
    "\n",
    "Библиотека `time`\n",
    "\n",
    "```python\n",
    "# засекаем время\n",
    "start_time = time.time()\n",
    "# подсчет времени выполнения\n",
    "lg_time_fit = time.time() - start_time\n",
    "# вывод в виде часов, минут, секунд\n",
    "time.strftime('%H:%M:%S', time.gmtime(lg_time_fit))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363055a9",
   "metadata": {
    "id": "363055a9"
   },
   "source": [
    "#### Метод `astype('datetime64[M]')`\n",
    "\n",
    "Альтернатива использованию класса `pd.DatetimeIndex`.  \n",
    "Обычно в датафреймах содержатся данные за несколько лет. Важно выбрать корректный метод для вычленения месяца, иначе месяца разных годов могут стать одним месяцем. Если года разные, то в новой колонке месяца у тебя отобразится первый день месяца ('2019-05-01'). Этот метод нужен для визуализации динамики по неделям, месяцам или годам (в зависимости от выбора метода).\n",
    "    \n",
    "Пример:\n",
    "```python\n",
    "df['first_day_exposition'].dt.date #приводим к временному формату\n",
    "df['first_day_exposition'].astype('datetime64[M]') \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1041eb1",
   "metadata": {},
   "source": [
    "#### Зафиксировать точку отсчета генератора случайных чисел\n",
    "\n",
    "```python\n",
    "# зададим точку отсчета\n",
    "np.random.seed(12345)\n",
    "# после этого сгенерированная случайная выборка будет постоянна\n",
    "\n",
    "# генерация нормального распределения из 1000 чисел\n",
    "# среднее значение 90, стандартное отклонение 20\n",
    "values = np.random.normal(90, 20, 1000)\n",
    "# построение гистограммы распределения, определение его параметров\n",
    "pd.Series(values).hist(bins=100)\n",
    "print(values.mean())\n",
    "print(values.std())\n",
    "print(np.quantile(values, 0.9))\n",
    "print(np.quantile(values, 0.1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434b0fa",
   "metadata": {
    "id": "d434b0fa"
   },
   "source": [
    "#### Метод `np.var()`\n",
    "\n",
    "Расчет дисперсии совокупности или выборки. Совокупность - это весь набор данных. Выборка - это часть набора данных по которой судят о совокупности. Дисперсия совокупности называется сигма в квадрате ($\\sigma^2$) и в формуле её расчета  в знаменателе стоит `(n)`. Дисперсия выборки называется эс в квадрате ($s^2$) и в формуле её расчета  в знаменателе стоит `(n-1)`.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6] # совокупность\n",
    "variance = np.var(x)\n",
    "print(variance) \n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6] # выборка\n",
    "variance_estimate = np.var(x, ddof=1) # указан параметр \"ddof=1\" для расчета дисперсии выборки (чтобы делилось на (n-1))\n",
    "print(variance_estimate) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b306e",
   "metadata": {
    "id": "c15b306e"
   },
   "source": [
    "#### Метод `np.std()`\n",
    "\n",
    "Расчет стандартного отклонения для совокупности и выборки. Стандартное отклонение ($\\sigma$) или ($s$) - это квадратный корень из дисперсии для совокупности или выборки соответственно.\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6]  # совокупность\n",
    "standard_deviation = np.std(x)\n",
    "print(standard_deviation)\n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6] # выборка\n",
    "standard_deviation = np.std(x, ddof=1) # указан параметр \"ddof=1\" для расчета дисперсии выборки (чтобы делилось на (n-1))\n",
    "print (standard_deviation) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4793f8",
   "metadata": {
    "id": "5e4793f8"
   },
   "source": [
    "#### Метод `np.sqrt()`\n",
    "\n",
    "Вычисление квадратного корня.\n",
    "```python\n",
    "import numpy as np\n",
    "variance = 2.9166666666666665\n",
    "standard_deviation = np.sqrt(variance)\n",
    "print(standard_deviation)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21fb64",
   "metadata": {},
   "source": [
    "#### Функция `diff()`\n",
    "\n",
    "Расчет производной в библиотеке `sympy`.\n",
    "\n",
    "```python\n",
    "# импорт библиотеки\n",
    "from sympy import *\n",
    "# определение переменных\n",
    "x = Symbol('x')\n",
    "y = Symbol('y')\n",
    "# определение функции f\n",
    "f = 1/2*(x-y)**2\n",
    "# взятие производной функции f по y\n",
    "print(diff(f, y))\n",
    "```\n",
    "результат:  \n",
    "```python\n",
    "-1.0*x + 1.0*y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f23fc",
   "metadata": {},
   "source": [
    "#### Бутстрап\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#np.random.seed(12345)\n",
    "\n",
    "# данные контрольной группы A\n",
    "samples_A = pd.Series([\n",
    "     98.24,  97.77,  95.56,  99.49, 101.4 , 105.35,  95.83,  93.02,\n",
    "    101.37,  95.66,  98.34, 100.75, 104.93,  97.  ,  95.46, 100.03,\n",
    "    102.34,  98.23,  97.05,  97.76,  98.63,  98.82,  99.51,  99.31,\n",
    "     98.58,  96.84,  93.71, 101.38, 100.6 , 103.68, 104.78, 101.51,\n",
    "    100.89, 102.27,  99.87,  94.83,  95.95, 105.2 ,  97.  ,  95.54,\n",
    "     98.38,  99.81, 103.34, 101.14, 102.19,  94.77,  94.74,  99.56,\n",
    "    102.  , 100.95, 102.19, 103.75, 103.65,  95.07, 103.53, 100.42,\n",
    "     98.09,  94.86, 101.47, 103.07, 100.15, 100.32, 100.89, 101.23,\n",
    "     95.95, 103.69, 100.09,  96.28,  96.11,  97.63,  99.45, 100.81,\n",
    "    102.18,  94.92,  98.89, 101.48, 101.29,  94.43, 101.55,  95.85,\n",
    "    100.16,  97.49, 105.17, 104.83, 101.9 , 100.56, 104.91,  94.17,\n",
    "    103.48, 100.55, 102.66, 100.62,  96.93, 102.67, 101.27,  98.56,\n",
    "    102.41, 100.69,  99.67, 100.99])\n",
    "#samples_A = pd.Series(np.random.normal(100, 4, size=(100))).round(2)\n",
    "\n",
    "# данные экспериментальной группы B\n",
    "samples_B = pd.Series([\n",
    "    101.67, 102.27,  97.01, 103.46, 100.76, 101.19,  99.11,  97.59,\n",
    "    101.01, 101.45,  94.8 , 101.55,  96.38,  99.03, 102.83,  97.32,\n",
    "     98.25,  97.17, 101.1 , 102.57, 104.59, 105.63,  98.93, 103.87,\n",
    "     98.48, 101.14, 102.24,  98.55, 105.61, 100.06,  99.  , 102.53,\n",
    "    101.56, 102.68, 103.26,  96.62,  99.48, 107.6 ,  99.87, 103.58,\n",
    "    105.05, 105.69,  94.52,  99.51,  99.81,  99.44,  97.35, 102.97,\n",
    "     99.77,  99.59, 102.12, 104.29,  98.31,  98.83,  96.83,  99.2 ,\n",
    "     97.88, 102.34, 102.04,  99.88,  99.69, 103.43, 100.71,  92.71,\n",
    "     99.99,  99.39,  99.19,  99.29, 100.34, 101.08, 100.29,  93.83,\n",
    "    103.63,  98.88, 105.36, 101.82, 100.86, 100.75,  99.4 ,  95.37,\n",
    "    107.96,  97.69, 102.17,  99.41,  98.97,  97.96,  98.31,  97.09,\n",
    "    103.92, 100.98, 102.76,  98.24,  97.  ,  98.99, 103.54,  99.72,\n",
    "    101.62, 100.62, 102.79, 104.19])\n",
    "#samples_B = pd.Series(np.random.normal(101, 4, size=(100))).round(2)\n",
    "\n",
    "# фактическая разность средних значений в группах\n",
    "AB_difference = samples_B.mean() - samples_A.mean() # < напишите код здесь >\n",
    "print('Разность средних чеков:', AB_difference)\n",
    "#print('Разность медиан чеков:', (samples_B.median() - samples_A.median()))\n",
    "\n",
    "alpha = 0.05\n",
    "    \n",
    "state = np.random.RandomState(12345)\n",
    "\n",
    "sredn = []\n",
    "bootstrap_samples = 1000\n",
    "count = 0\n",
    "for i in range(bootstrap_samples):\n",
    "    # объедините выборки\n",
    "    united_samples = pd.concat([samples_A, samples_B]) # < напишите код здесь >\n",
    "\n",
    "    # создайте подвыборку\n",
    "    subsample = united_samples.sample(frac=1, replace=True, random_state=state) # < напишите код здесь >\n",
    "    \n",
    "    # разбейте подвыборку пополам\n",
    "    subsample_A = subsample[:len(samples_A)] # < напишите код здесь >\n",
    "    subsample_B = subsample[len(samples_A):] # < напишите код здесь >\n",
    "\n",
    "    # найдите разницу средних\n",
    "    bootstrap_difference = subsample_B.mean() - subsample_A.mean() # < напишите код здесь >\n",
    "    sredn.append(bootstrap_difference)\n",
    "\n",
    "    # если разница не меньше фактической, увеличиваем счётчик\n",
    "    if bootstrap_difference >= AB_difference:\n",
    "        count += 1\n",
    "\n",
    "# p-value равно доле превышений значений\n",
    "pvalue = 1. * count / bootstrap_samples\n",
    "print('p-value =', pvalue)\n",
    "\n",
    "if pvalue < alpha:\n",
    "    print(\"Отвергаем нулевую гипотезу: скорее всего, средний чек увеличился\")\n",
    "else:\n",
    "    print(\"Не получилось отвергнуть нулевую гипотезу: скорее всего, средний чек не увеличился\")\n",
    "\n",
    "sredn = pd.Series(data=sredn)\n",
    "sredn.hist(bins=100)\n",
    "plt.axvline (x=AB_difference, color='red', linestyle='--')\n",
    "plt.show()\n",
    "sredn.describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e69b4d",
   "metadata": {},
   "source": [
    "#### Редкие и аномальные значения.\n",
    "\n",
    "Эти значения рекомендуется удалять.  \n",
    "Они определяются \"на глаз\" по гистограммам отсекая хвосты, либо отсекается все что выходит за усы `boxplot`, либо находят диапазоны через квантили:\n",
    "\n",
    "```python\n",
    "lower_bound = table[col].quantile(q = 0.025)\n",
    "upper_bound = table[col].quantile(q = 0.975)\n",
    "```\n",
    "Во всех этих методах удаляем выбросы, приняв за аксиому, что у нас должно быть нормальное распределение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f58309",
   "metadata": {},
   "source": [
    "#### Библиотеки для обзора и анализа датасетов `pandas_profiling` и `sweetviz`\n",
    "\n",
    "Позволяет сделать обзор датасета (`data`) одной командой.\n",
    "\n",
    "Pandas Profiling\n",
    "\n",
    "Ссылка на страницу с описанием в GitHab: https://github.com/revirevy/pandas-profiling\n",
    "\n",
    "```python\n",
    "# 1. загрузка и установка\n",
    "# вариант 1:\n",
    "pip install pandas_profiling\n",
    "# вариант 2:\n",
    "pip install pandas-profiling[notebook,html]\n",
    "# вариант 3 установка прямо с GitHab:\n",
    "pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n",
    "\n",
    "# 2. импорт\n",
    "# вариант 1:\n",
    "import pandas_profiling\n",
    "# который может выдавать ошибку, просить дополнительный импорт 'ydata_profiling':\n",
    "import ydata_profiling\n",
    "# вариант 2 сразу импортировать класс:\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# требует импорта:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 3. применение\n",
    "# вариант 1:\n",
    "data.profile_report()\n",
    "# вариант 2:\n",
    "profile = ProfileReport(df, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n",
    "\n",
    "# создание интерактивного отчета в Jupyter Notebook (в Visual Studio Code ничего не отображал):\n",
    "profile.to_widgets()\n",
    "# или интерактивный отчет в Jupyter Notebook в виде html (в Visual Studio Code отображал тоже самое, что и обычное применение):\n",
    "profile.to_notebook_iframe()\n",
    "\n",
    "# сохранение в виде html файла:\n",
    "profile.to_file(output_file=\"your_report.html\")\n",
    "# сохранение в виде json файла:\n",
    "profile.to_file(output_file=\"your_report.json\")\n",
    "# или:\n",
    "json_data = profile.to_json()\n",
    "```\n",
    "\n",
    "SweetVIZ\n",
    "\n",
    "Ссылка на страницу с описанием: https://pypi.org/project/sweetviz/\n",
    "\n",
    "```python\n",
    "# 1. загрузка и установка\n",
    "pip install sweetviz\n",
    "\n",
    "# 2. импорт\n",
    "import sweetviz as sw\n",
    "\n",
    "# 3. применение\n",
    "analyze_report = sw.analyze(data)\n",
    "# отображение в ячейке Jupyter Notebook:\n",
    "analyze_report.show_notebook(w=None, h=None, scale=None, layout='widescreen', filepath=None)\n",
    "# сохранение результата в html:\n",
    "analyze_report.show_html(filepath='output.html', open_browser=True, layout='widescreen', scale=None)\n",
    "\n",
    "# 4. сравнение двух датасетов:\n",
    "my_report = sv.compare([my_dataframe, \"Training Data\"], [test_df, \"Test Data\"], \"Survived\", feature_config)\n",
    "\n",
    "# 5. сравнение подмножеств внутри одного датасета:\n",
    "my_report = sv.compare_intra(my_dataframe, my_dataframe[\"Sex\"] == \"male\", [\"Male\", \"Female\"], feature_config)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f4e713",
   "metadata": {},
   "source": [
    "#### Распараллеливание выполнения команд для ускорения.\n",
    "\n",
    "Применяется библиотека `pandarallel`. Распределяет вычисления не на один, а по всем доступным процессорам. Но при этом требует в два раза больше оперативной памяти. Можно ускорить выполнение некоторых команд `pandas`, заменяя их командами `pandarallel`.\n",
    "\n",
    "Перечень распараллеливаемых команд:\n",
    "\n",
    "|Без распараллеливания | С распараллеливанием |\n",
    "|----------------------|----------------------|\n",
    "df.apply(func) | df.parallel_apply(func)\n",
    "df.applymap(func) | df.parallel_applymap(func)\n",
    "df.groupby(args).apply(func) | df.groupby(args).parallel_apply(func)\n",
    "df.groupby(args1).col_name.rolling(args2).apply(func) | df.groupby(args1).col_name.rolling(args2).parallel_apply(func)\n",
    "df.groupby(args1).col_name.expanding(args2).apply(func) | df.groupby(args1).col_name.expanding(args2).parallel_apply(func)\n",
    "series.map(func) | series.parallel_map(func)\n",
    "series.apply(func) | series.parallel_apply(func)\n",
    "series.rolling(args).apply(func) | series.rolling(args).parallel_apply(func)\n",
    "\n",
    "\n",
    "```python\n",
    "# импорт библиотеки\n",
    "from pandarallel import pandarallel\n",
    "# инициализация процессов распараллеливания\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "# применение метода apply\n",
    "df.parallel_apply(func)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "998d7648dd755371a7ba8fe881a42807a5528e9c57c793fb17dd78daafcc3440"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
